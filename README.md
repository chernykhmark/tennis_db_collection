# Tennis Data Pipeline

## Описание
Проект предназнчаен для сбора данных о предстоящих и будущих теннисных матчей с целью анализа и прогнозирования вероятностных исходов


## Ход выполнения проекта

### Этап 1

1. реализован скрипт парсинга данных с сайта eurosport, скрипт собирает определенные данные о предстоящих матчах и складывет их в sqllite, уведомляет пользователя в телеграм о том что появлился новый матч, присылает ему высчитанный прогноз. Переодически скрипт проверяет закончился ли матч и парсит его результат. 
система работает автономно на linux сервере. 

2. добавлен новый источник сайт flashscore, откуда дважды в день мы получем данные о будущих и прошедших мачтах. данные не преобрабатываются на лету, а складываются в виде словаря и html строки as is. 
затем скрипт [get_flashscore_directory_to_mongo.py](scripts/get_flashscore_directory_to_mongo.py) забирает данные из директории и складывает в коллекцию mongo, где в дальнейшем преобразуется, разделяясь на отдельные объекты коллекции matches.
Скрипт [get_mongo_links_and_bring_back_html.py](scripts/get_mongo_links_and_bring_back_html.py) находит все документы с играми, забирает из них ссылки, по которым забирает html строки с данными о матче as is и добавляет как атрибут того же документа.

был развернут контейнер mongo + postgres + airflow + metabase
* в данный момент стало понятно что сервер не расчитан на большую нагрузку. всязи с чем postgres + airflow + metabase будут работать на другом сервере.

# Бэклог:

- организовать упорядоченное хранение данных в postgres и упорядочить загрузку через airflow 
- отобразить витрины данных с статистикой в metabase
- использовать ML модели  